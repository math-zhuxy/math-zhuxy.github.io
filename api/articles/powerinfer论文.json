{"title":"PowerInfer论文","uid":"1150f8d04ea2174e83f737731d4cd296","slug":"powerinfer论文","date":"2024-11-19T12:30:31.000Z","updated":"2024-11-19T14:22:04.803Z","comments":true,"path":"api/articles/powerinfer论文.json","keywords":null,"cover":null,"content":"<p><a href=\"https://dl.acm.org/doi/pdf/10.1145/3694715.3695964\">论文原文链接</a></p>\n<h1 id=\"论文核心内容\"><a href=\"#论文核心内容\" class=\"headerlink\" title=\"论文核心内容\"></a>论文核心内容</h1><ol>\n<li>目标解决在消费级GPU上高效运行LLM的问题，特别是模型的高显存需求对现有硬件的限制。</li>\n<li>核心思想利用LLM推理过程中神经元激活的稀疏性和局部性，通过<strong>GPU-CPU混合推理引擎</strong>将经常活跃的神经元（热神经元）预加载到GPU上，而较少活跃的神经元（冷神经元）则由CPU计算，从而减小显存压力并优化数据传输。</li>\n<li>技术亮点</li>\n</ol>\n<ul>\n<li>局部性利用： LLM中的神经元激活具有skewed power-law distribution，少量热神经元贡献了大部分计算量。</li>\n<li>稀疏推理： 通过设计自适应预测器和神经元感知的稀疏运算算子，只对被预测为激活的神经元进行计算。</li>\n<li>优化数据分配： 提出了一种离线策略生成器，用于根据神经元的重要性和硬件特性决定其分配到GPU或CPU。</li>\n</ul>\n<h1 id=\"技术细节\"><a href=\"#技术细节\" class=\"headerlink\" title=\"技术细节\"></a>技术细节</h1><h2 id=\"架构设计\"><a href=\"#架构设计\" class=\"headerlink\" title=\"架构设计\"></a>架构设计</h2><h3 id=\"离线阶段：\"><a href=\"#离线阶段：\" class=\"headerlink\" title=\"离线阶段：\"></a>离线阶段：</h3><ul>\n<li>神经元划分：<ul>\n<li>使用general datasets（如C4、Wikipedia）对模型进行分析，统计每个神经元的激活频率。</li>\n<li>将激活频率高的神经元标记为<strong>热神经元</strong>，频率低的标记为<strong>冷神经元</strong>。</li>\n<li>热神经元预加载到GPU，而冷神经元留在CPU上，减少了GPU显存需求。</li>\n</ul>\n</li>\n<li>稀疏预测器的训练：<ul>\n<li>利用离线分析数据，训练一个在线预测器，用于推理过程中动态预测当前输入将激活的神经元。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"在线阶段：\"><a href=\"#在线阶段：\" class=\"headerlink\" title=\"在线阶段：\"></a>在线阶段：</h3><ul>\n<li>动态预测神经元激活：<ul>\n<li>对每一层的神经元，稀疏推理引擎通过预测器判断哪些神经元可能被激活。</li>\n<li>仅计算被预测为激活的神经元，跳过非激活神经元，显著减少计算量。</li>\n</ul>\n</li>\n<li>分布式处理：<ul>\n<li>GPU负责计算热神经元，这些神经元频繁被激活，对推理结果影响大。</li>\n<li>CPU负责处理冷神经元，这些神经元较少被激活，避免GPU资源浪费。</li>\n</ul>\n</li>\n<li>GPU-CPU协同工作：<ul>\n<li>GPU和CPU同时运行各自的神经元计算，结果通过优化的同步操作整合。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"关键模块：\"><a href=\"#关键模块：\" class=\"headerlink\" title=\"关键模块：\"></a>关键模块：</h3><ol>\n<li>神经元预测器：动态预测哪些神经元会在当前输入下被激活，避免计算冗余。</li>\n<li>稀疏算子：基于神经元的矢量运算优化了传统稀疏矩阵运算。</li>\n<li>GPU-CPU协同处理：为每个推理任务分配独立线程，实现并行推理。</li>\n</ol>\n<h2 id=\"具体实现\"><a href=\"#具体实现\" class=\"headerlink\" title=\"具体实现\"></a>具体实现</h2><h3 id=\"离线阶段：如何分析热-冷神经元\"><a href=\"#离线阶段：如何分析热-冷神经元\" class=\"headerlink\" title=\"离线阶段：如何分析热&#x2F;冷神经元\"></a>离线阶段：如何分析热&#x2F;冷神经元</h3><h4 id=\"数据集选择与输入生成：\"><a href=\"#数据集选择与输入生成：\" class=\"headerlink\" title=\"数据集选择与输入生成：\"></a>数据集选择与输入生成：</h4><p>使用通用数据集（如C4和Wikipedia）生成大规模输入序列，这些数据具有广泛的代表性，用于模拟模型在真实场景下的推理行为。</p>\n<h4 id=\"激活监控：\"><a href=\"#激活监控：\" class=\"headerlink\" title=\"激活监控：\"></a>激活监控：</h4><p>在Transformer每一层的各个块（如MLP块或自注意力块）后插入monitoring kernel，动态记录每次推理中每个神经元的激活状态。</p>\n<h4 id=\"统计激活频率\"><a href=\"#统计激活频率\" class=\"headerlink\" title=\"统计激活频率:\"></a>统计激活频率:</h4><p>神经元的激活由激活函数（如ReLU或SwiGLU）决定，当某个神经元的输出值不为零时，视为激活。通过多次推理，统计每个神经元的激活频率。</p>\n<h4 id=\"热-冷神经元划分：\"><a href=\"#热-冷神经元划分：\" class=\"headerlink\" title=\"热&#x2F;冷神经元划分：\"></a>热&#x2F;冷神经元划分：</h4><p>基于统计结果，观察神经元的激活遵循<strong>幂律分布</strong>，即少量神经元的激活频率高，这些神经元被标记为热神经元。  其余神经元（大部分激活频率较低）被标记为冷神经元。</p>\n<h4 id=\"热神经元的一致性分析：\"><a href=\"#热神经元的一致性分析：\" class=\"headerlink\" title=\"热神经元的一致性分析：\"></a>热神经元的一致性分析：</h4><p>为验证热神经元是否稳定地在不同任务和输入中保持高激活频率，论文进一步通过多个任务（如知识问答、逻辑推理）的测试，发现热神经元在不同场景下激活的重叠度超过90%，证明这些神经元具有任务无关的稳定性。</p>\n<h3 id=\"在线阶段：Sparse-operator-optimization\"><a href=\"#在线阶段：Sparse-operator-optimization\" class=\"headerlink\" title=\"在线阶段：Sparse operator optimization\"></a>在线阶段：Sparse operator optimization</h3><h4 id=\"Neuron-aware-Sparse-Operators：\"><a href=\"#Neuron-aware-Sparse-Operators：\" class=\"headerlink\" title=\"Neuron-aware Sparse Operators：\"></a>Neuron-aware Sparse Operators：</h4><ul>\n<li>在推理过程中，矩阵运算通常涉及大量零值，直接跳过这些零值运算可以减少不必要的计算。</li>\n<li>论文提出了一种神经元感知稀疏算子，专门优化矩阵-向量运算：<ul>\n<li>GPU稀疏算子： 每个线程块处理一个神经元集合，独立检查是否激活并计算，避免了对稀疏矩阵的格式转换。</li>\n<li>CPU稀疏算子： 利用CPU的矢量扩展指令（如AVX2）对小批量激活神经元进行并行计算。</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"稀疏推理流程的优化：\"><a href=\"#稀疏推理流程的优化：\" class=\"headerlink\" title=\"稀疏推理流程的优化：\"></a>稀疏推理流程的优化：</h4><ul>\n<li>预测器优化：<ul>\n<li>根据每层的激活稀疏性和偏斜性调整预测器大小，确保高预测精度的同时降低GPU内存占用。</li>\n</ul>\n</li>\n<li>计算图优化：<ul>\n<li>构建基于稀疏性和依赖关系的计算图（DAG），在推理时动态调度计算任务。</li>\n</ul>\n</li>\n<li>同步与结果合并：<ul>\n<li>GPU和CPU分别计算后，通过高效的稀疏结果合并操作，将结果汇总到GPU。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"在线阶段：同步操作\"><a href=\"#在线阶段：同步操作\" class=\"headerlink\" title=\"在线阶段：同步操作\"></a>在线阶段：同步操作</h3><p><strong>计算任务分离与并行化</strong>：</p>\n<ul>\n<li><p>热神经元与冷神经元的分离计算：GPU和CPU各自独立计算属于自己负责的神经元（GPU负责热神经元，CPU负责冷神经元），在计算过程中无需频繁通信，从而减少PCIe数据传输开销。</p>\n</li>\n<li><p>独立线程管理：使用线程池并行化GPU和CPU上的神经元计算任务，尽量充分利用两种处理器的资源，避免同步时的阻塞。</p>\n</li>\n</ul>\n<p><strong>依赖管理与计算调度</strong></p>\n<ul>\n<li>构建一个计算任务的有向无环图（DAG），每个计算任务（如矩阵乘法、激活函数运算）作为图中的节点。</li>\n<li>任务依赖检查：<ul>\n<li>在同步操作前，通过依赖检查确认所有GPU任务或CPU任务的前置计算是否已完成。</li>\n<li>避免未完成任务导致的阻塞或错误结果。</li>\n</ul>\n</li>\n<li>任务优先级分配：<br>优先处理对后续任务有直接依赖的神经元，以减少同步等待。</li>\n</ul>\n<p><strong>结果合并（Reduce操作）</strong></p>\n<ul>\n<li>GPU主导合并：<ul>\n<li>合并操作始终在GPU上进行，因为GPU更擅长处理大规模并行计算。</li>\n<li>CPU计算的冷神经元结果通过PCIe传输到GPU，并与GPU自身计算的热神经元结果一起完成最终的整合。</li>\n</ul>\n</li>\n<li>稀疏合并优化：<ul>\n<li>只传输和合并实际被激活的神经元结果，跳过未激活神经元对应的零值，进一步减少通信量和计算量。</li>\n</ul>\n</li>\n</ul>\n<p><strong>异步通信与重叠计算</strong></p>\n<ul>\n<li>异步数据传输：<ul>\n<li>使用CUDA异步API（如cudaMemcpyAsync）在CPU完成冷神经元计算后立即开始传输数据到GPU，同时GPU继续处理其他任务，充分利用传输和计算的时间重叠。</li>\n</ul>\n</li>\n<li>动态任务平衡：<br>如果CPU完成任务速度较慢，GPU可以动态调整其负载，帮助处理部分冷神经元任务。</li>\n</ul>\n<p><strong>同步点优化（Barrier）</strong></p>\n<ul>\n<li>GPU与CPU在每层神经元计算结束后只进行一次结果同步，而不是在每一步操作后同步。</li>\n<li>最小化同步次数：<br>通过提前规划任务依赖和合并逻辑，确保同步点尽量少，且只在必要时触发。</li>\n</ul>\n","feature":true,"text":"论文原文链接 论文核心内容 目标解决在消费级GPU上高效运行LLM的问题，特别是模型的高显存需求对现有硬件的限制。 核心思想利用LLM推理过程中神经元激活的稀疏...","permalink":"/post/powerinfer论文","photos":[],"count_time":{"symbolsCount":"2.5k","symbolsTime":"2 mins."},"categories":[],"tags":[{"name":"论文阅读","slug":"论文阅读","count":1,"path":"api/tags/论文阅读.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E8%AE%BA%E6%96%87%E6%A0%B8%E5%BF%83%E5%86%85%E5%AE%B9\"><span class=\"toc-text\">论文核心内容</span></a></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E6%8A%80%E6%9C%AF%E7%BB%86%E8%8A%82\"><span class=\"toc-text\">技术细节</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1\"><span class=\"toc-text\">架构设计</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E7%A6%BB%E7%BA%BF%E9%98%B6%E6%AE%B5%EF%BC%9A\"><span class=\"toc-text\">离线阶段：</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E5%9C%A8%E7%BA%BF%E9%98%B6%E6%AE%B5%EF%BC%9A\"><span class=\"toc-text\">在线阶段：</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E5%85%B3%E9%94%AE%E6%A8%A1%E5%9D%97%EF%BC%9A\"><span class=\"toc-text\">关键模块：</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E5%85%B7%E4%BD%93%E5%AE%9E%E7%8E%B0\"><span class=\"toc-text\">具体实现</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E7%A6%BB%E7%BA%BF%E9%98%B6%E6%AE%B5%EF%BC%9A%E5%A6%82%E4%BD%95%E5%88%86%E6%9E%90%E7%83%AD-%E5%86%B7%E7%A5%9E%E7%BB%8F%E5%85%83\"><span class=\"toc-text\">离线阶段：如何分析热&#x2F;冷神经元</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E6%95%B0%E6%8D%AE%E9%9B%86%E9%80%89%E6%8B%A9%E4%B8%8E%E8%BE%93%E5%85%A5%E7%94%9F%E6%88%90%EF%BC%9A\"><span class=\"toc-text\">数据集选择与输入生成：</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E6%BF%80%E6%B4%BB%E7%9B%91%E6%8E%A7%EF%BC%9A\"><span class=\"toc-text\">激活监控：</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E7%BB%9F%E8%AE%A1%E6%BF%80%E6%B4%BB%E9%A2%91%E7%8E%87\"><span class=\"toc-text\">统计激活频率:</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E7%83%AD-%E5%86%B7%E7%A5%9E%E7%BB%8F%E5%85%83%E5%88%92%E5%88%86%EF%BC%9A\"><span class=\"toc-text\">热&#x2F;冷神经元划分：</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E7%83%AD%E7%A5%9E%E7%BB%8F%E5%85%83%E7%9A%84%E4%B8%80%E8%87%B4%E6%80%A7%E5%88%86%E6%9E%90%EF%BC%9A\"><span class=\"toc-text\">热神经元的一致性分析：</span></a></li></ol></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E5%9C%A8%E7%BA%BF%E9%98%B6%E6%AE%B5%EF%BC%9ASparse-operator-optimization\"><span class=\"toc-text\">在线阶段：Sparse operator optimization</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#Neuron-aware-Sparse-Operators%EF%BC%9A\"><span class=\"toc-text\">Neuron-aware Sparse Operators：</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E7%A8%80%E7%96%8F%E6%8E%A8%E7%90%86%E6%B5%81%E7%A8%8B%E7%9A%84%E4%BC%98%E5%8C%96%EF%BC%9A\"><span class=\"toc-text\">稀疏推理流程的优化：</span></a></li></ol></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E5%9C%A8%E7%BA%BF%E9%98%B6%E6%AE%B5%EF%BC%9A%E5%90%8C%E6%AD%A5%E6%93%8D%E4%BD%9C\"><span class=\"toc-text\">在线阶段：同步操作</span></a></li></ol></li></ol></li></ol>","author":{"name":"Math-zhuxy","slug":"blog-author","avatar":"https://sse-market-source-1320172928.cos.ap-guangzhou.myqcloud.com/src/images/uploads/1728918801765528128_%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20241014222719.jpg","link":"/","description":"Blood of the First Men, drawn by the sword.","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"mapped":true,"hidden":false,"prev_post":{"title":"MST","uid":"ac69b4c1992072269abea91444d26b98","slug":"MST","date":"2024-11-21T01:56:04.000Z","updated":"2024-11-21T08:21:55.038Z","comments":true,"path":"api/articles/MST.json","keywords":null,"cover":null,"text":"MST定义设 $G=(V,E)$ 是一个无向连通图，$E$ 中的每个权值 $c(u,v)$ ，称为 $(u,v)$ 的边长。图 $G$ 的生成树( $n-1$ ...","permalink":"/post/MST","photos":[],"count_time":{"symbolsCount":"3.5k","symbolsTime":"3 mins."},"categories":[],"tags":[{"name":"算法","slug":"算法","count":15,"path":"api/tags/算法.json"}],"author":{"name":"Math-zhuxy","slug":"blog-author","avatar":"https://sse-market-source-1320172928.cos.ap-guangzhou.myqcloud.com/src/images/uploads/1728918801765528128_%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20241014222719.jpg","link":"/","description":"Blood of the First Men, drawn by the sword.","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"feature":true},"next_post":{"title":"配置极光主题","uid":"a8b6b9bbf4052440f27a448efb8e5b47","slug":"极光主题配置","date":"2024-11-17T14:44:01.000Z","updated":"2024-11-17T15:09:08.459Z","comments":true,"path":"api/articles/极光主题配置.json","keywords":null,"cover":null,"text":"下载HEXO首先要先下载npm，在Node.js官网下载LTS版本到本地。下载好后，在命令行中输入： 1npm -v 来查看版本如果之前已经下载过了，但是版本落...","permalink":"/post/极光主题配置","photos":[],"count_time":{"symbolsCount":"2.6k","symbolsTime":"2 mins."},"categories":[],"tags":[{"name":"配置","slug":"配置","count":2,"path":"api/tags/配置.json"}],"author":{"name":"Math-zhuxy","slug":"blog-author","avatar":"https://sse-market-source-1320172928.cos.ap-guangzhou.myqcloud.com/src/images/uploads/1728918801765528128_%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20241014222719.jpg","link":"/","description":"Blood of the First Men, drawn by the sword.","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}}}}